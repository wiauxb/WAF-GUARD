{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test ModSec Analyzer\n",
    "\n",
    "Notebook pour tester le module `modsec_analyzer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajouter le package au path\n",
    "import sys\n",
    "sys.path.insert(0, \"packages/modsec_analyzer/src\")\n",
    "\n",
    "# Autoreload pour recharger les modules modifiés\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from modsec_analyzer.parsing import parse_file\n",
    "from modsec_analyzer.domain import (\n",
    "    Rule, SecRule, SecAction, Directive,\n",
    "    Variable, Operator, Action, Argument,\n",
    "    RuleSet\n",
    ")\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemin vers un fichier de configuration CRS\n",
    "# Modifier ce chemin selon votre installation\n",
    "CRS_PATH = \"config/modsecurity/setup.conf\"\n",
    "# ou un fichier de règles spécifique\n",
    "# CRS_PATH = \"/path/to/coreruleset/rules/REQUEST-942-APPLICATION-ATTACK-SQLI.conf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test parsing avec résolution des includes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/lucas/reforge/WAF-GUARD/experiments/experiments/config/modsecurity/setup.conf'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Parser avec résolution des includes (peut prendre quelques secondes)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m ruleset_full = \u001b[43mparse_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCRS_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolve_includes\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNombre total de rules: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(ruleset_full.rules)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/reforge/WAF-GUARD/experiments/packages/modsec_analyzer/src/modsec_analyzer/parsing/msc_adapter.py:37\u001b[39m, in \u001b[36mparse_file\u001b[39m\u001b[34m(filepath, resolve_includes, include_comments)\u001b[39m\n\u001b[32m     34\u001b[39m rules = []\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m resolve_includes:\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     files_data = \u001b[43m_resolve_includes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     39\u001b[39m     files_data = [(filepath, _parse_single_file(filepath))]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/reforge/WAF-GUARD/experiments/packages/modsec_analyzer/src/modsec_analyzer/parsing/msc_adapter.py:93\u001b[39m, in \u001b[36m_resolve_includes\u001b[39m\u001b[34m(entry_file)\u001b[39m\n\u001b[32m     90\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m     91\u001b[39m visited.add(filepath)\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m configlines = \u001b[43m_parse_single_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m result.append((filepath, configlines))\n\u001b[32m     96\u001b[39m \u001b[38;5;66;03m# Find include directives and collect files to insert\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/reforge/WAF-GUARD/experiments/packages/modsec_analyzer/src/modsec_analyzer/parsing/msc_adapter.py:62\u001b[39m, in \u001b[36m_parse_single_file\u001b[39m\u001b[34m(filepath)\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_parse_single_file\u001b[39m(filepath: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m]:\n\u001b[32m     53\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     54\u001b[39m \u001b[33;03m    Parse a single file and return raw configlines from msc_pyparser.\u001b[39;00m\n\u001b[32m     55\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     60\u001b[39m \u001b[33;03m        List of parsed directive dicts\u001b[39;00m\n\u001b[32m     61\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m     content = \u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m     mparser = msc_pyparser.MSCParser()\n\u001b[32m     64\u001b[39m     mparser.parser.parse(content)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/pathlib.py:1029\u001b[39m, in \u001b[36mPath.read_text\u001b[39m\u001b[34m(self, encoding, errors)\u001b[39m\n\u001b[32m   1025\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1026\u001b[39m \u001b[33;03mOpen the file in text mode, read it, and close the file.\u001b[39;00m\n\u001b[32m   1027\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1028\u001b[39m encoding = io.text_encoding(encoding)\n\u001b[32m-> \u001b[39m\u001b[32m1029\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m   1030\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m f.read()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/pathlib.py:1015\u001b[39m, in \u001b[36mPath.open\u001b[39m\u001b[34m(self, mode, buffering, encoding, errors, newline)\u001b[39m\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1014\u001b[39m     encoding = io.text_encoding(encoding)\n\u001b[32m-> \u001b[39m\u001b[32m1015\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffering\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/home/lucas/reforge/WAF-GUARD/experiments/experiments/config/modsecurity/setup.conf'"
     ]
    }
   ],
   "source": [
    "# Parser avec résolution des includes (peut prendre quelques secondes)\n",
    "ruleset_full = parse_file(CRS_PATH, resolve_includes=True)\n",
    "\n",
    "print(f\"Nombre total de rules: {len(ruleset_full.rules)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fichiers parsés (28):\n",
      "  /home/lucas/reforge/WAF-GUARD/experiments/config/modsecurity/crs-setup.conf\n",
      "  /home/lucas/reforge/WAF-GUARD/experiments/config/modsecurity/crs_rules/REQUEST-901-INITIALIZATION.conf\n",
      "  /home/lucas/reforge/WAF-GUARD/experiments/config/modsecurity/crs_rules/REQUEST-905-COMMON-EXCEPTIONS.conf\n",
      "  /home/lucas/reforge/WAF-GUARD/experiments/config/modsecurity/crs_rules/REQUEST-911-METHOD-ENFORCEMENT.conf\n",
      "  /home/lucas/reforge/WAF-GUARD/experiments/config/modsecurity/crs_rules/REQUEST-913-SCANNER-DETECTION.conf\n",
      "  /home/lucas/reforge/WAF-GUARD/experiments/config/modsecurity/crs_rules/REQUEST-920-PROTOCOL-ENFORCEMENT.conf\n",
      "  /home/lucas/reforge/WAF-GUARD/experiments/config/modsecurity/crs_rules/REQUEST-921-PROTOCOL-ATTACK.conf\n",
      "  /home/lucas/reforge/WAF-GUARD/experiments/config/modsecurity/crs_rules/REQUEST-922-MULTIPART-ATTACK.conf\n",
      "  /home/lucas/reforge/WAF-GUARD/experiments/config/modsecurity/crs_rules/REQUEST-930-APPLICATION-ATTACK-LFI.conf\n",
      "  /home/lucas/reforge/WAF-GUARD/experiments/config/modsecurity/crs_rules/REQUEST-931-APPLICATION-ATTACK-RFI.conf\n",
      "  /home/lucas/reforge/WAF-GUARD/experiments/config/modsecurity/crs_rules/REQUEST-932-APPLICATION-ATTACK-RCE.conf\n",
      "  /home/lucas/reforge/WAF-GUARD/experiments/config/modsecurity/crs_rules/REQUEST-933-APPLICATION-ATTACK-PHP.conf\n",
      "  /home/lucas/reforge/WAF-GUARD/experiments/config/modsecurity/crs_rules/REQUEST-934-APPLICATION-ATTACK-GENERIC.conf\n",
      "  /home/lucas/reforge/WAF-GUARD/experiments/config/modsecurity/crs_rules/REQUEST-941-APPLICATION-ATTACK-XSS.conf\n",
      "  /home/lucas/reforge/WAF-GUARD/experiments/config/modsecurity/crs_rules/REQUEST-942-APPLICATION-ATTACK-SQLI.conf\n",
      "  /home/lucas/reforge/WAF-GUARD/experiments/config/modsecurity/crs_rules/REQUEST-943-APPLICATION-ATTACK-SESSION-FIXATION.conf\n",
      "  /home/lucas/reforge/WAF-GUARD/experiments/config/modsecurity/crs_rules/REQUEST-944-APPLICATION-ATTACK-JAVA.conf\n",
      "  /home/lucas/reforge/WAF-GUARD/experiments/config/modsecurity/crs_rules/REQUEST-949-BLOCKING-EVALUATION.conf\n",
      "  /home/lucas/reforge/WAF-GUARD/experiments/config/modsecurity/crs_rules/RESPONSE-950-DATA-LEAKAGES.conf\n",
      "  /home/lucas/reforge/WAF-GUARD/experiments/config/modsecurity/crs_rules/RESPONSE-951-DATA-LEAKAGES-SQL.conf\n",
      "  /home/lucas/reforge/WAF-GUARD/experiments/config/modsecurity/crs_rules/RESPONSE-952-DATA-LEAKAGES-JAVA.conf\n",
      "  /home/lucas/reforge/WAF-GUARD/experiments/config/modsecurity/crs_rules/RESPONSE-953-DATA-LEAKAGES-PHP.conf\n",
      "  /home/lucas/reforge/WAF-GUARD/experiments/config/modsecurity/crs_rules/RESPONSE-954-DATA-LEAKAGES-IIS.conf\n",
      "  /home/lucas/reforge/WAF-GUARD/experiments/config/modsecurity/crs_rules/RESPONSE-955-WEB-SHELLS.conf\n",
      "  /home/lucas/reforge/WAF-GUARD/experiments/config/modsecurity/crs_rules/RESPONSE-956-DATA-LEAKAGES-RUBY.conf\n",
      "  /home/lucas/reforge/WAF-GUARD/experiments/config/modsecurity/crs_rules/RESPONSE-959-BLOCKING-EVALUATION.conf\n",
      "  /home/lucas/reforge/WAF-GUARD/experiments/config/modsecurity/crs_rules/RESPONSE-980-CORRELATION.conf\n",
      "  /home/lucas/reforge/WAF-GUARD/experiments/config/modsecurity/setup.conf\n"
     ]
    }
   ],
   "source": [
    "# Fichiers sources uniques\n",
    "unique_files = set(rule.file_path for rule in ruleset_full.rules)\n",
    "print(f\"\\nFichiers parsés ({len(unique_files)}):\")\n",
    "for f in sorted(unique_files):\n",
    "    print(f\"  {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RuleSet (715 rules from 26 file(s))\n",
      "  Types:\n",
      "    SecRule: 677\n",
      "    SecMarker: 30\n",
      "    SecAction: 7\n",
      "    SecComponentSignature: 1\n",
      "\n",
      "  Tags:\n",
      "    attack:\n",
      "      rce: 90\n",
      "      protocol: 74\n",
      "      sqli: 60\n",
      "      xss: 33\n",
      "      disclosure: 33\n",
      "      injection-php: 20\n",
      "      injection-generic: 7\n",
      "      multipart-header: 6\n",
      "      lfi: 5\n",
      "      rfi: 5\n",
      "      generic: 3\n",
      "      ssrf: 3\n",
      "      fixation: 3\n",
      "      reputation-scanner: 1\n",
      "      deprecated-header: 1\n",
      "      ssti: 1\n",
      "      injection-java: 1\n",
      "      (no tag): 347\n",
      "    application:\n",
      "      multi: 308\n",
      "      (no tag): 376\n",
      "    language:\n",
      "      multi: 218\n",
      "      php: 52\n",
      "      shell: 33\n",
      "      java: 15\n",
      "      javascript: 4\n",
      "      ruby: 3\n",
      "      aspnet: 2\n",
      "      ldap: 1\n",
      "      powershell: 1\n",
      "      perl: 1\n",
      "      (no tag): 355\n",
      "    platform:\n",
      "      multi: 254\n",
      "      unix: 27\n",
      "      windows: 13\n",
      "      internet-explorer: 13\n",
      "      iis: 6\n",
      "      nodejs: 5\n",
      "      apache: 3\n",
      "      tomcat: 1\n",
      "      msaccess: 1\n",
      "      oracle: 1\n",
      "      db2: 1\n",
      "      emc: 1\n",
      "      firebird: 1\n",
      "      frontbase: 1\n",
      "      hsqldb: 1\n",
      "      informix: 1\n",
      "      ingres: 1\n",
      "      interbase: 1\n",
      "      maxdb: 1\n",
      "      mssql: 1\n",
      "      mysql: 1\n",
      "      pgsql: 1\n",
      "      sqlite: 1\n",
      "      sybase: 1\n",
      "      (no tag): 353\n"
     ]
    }
   ],
   "source": [
    "print(ruleset_full.filter(filename=\"crs_rules\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Règles pour la phase 1 : 173\n",
      "\n",
      "Règles pour la phase 2 : 280\n",
      "\n",
      "Règles pour la phase 3 : 43\n",
      "\n",
      "Règles pour la phase 4 : 109\n",
      "\n",
      "Règles pour la phase 5 : 13\n",
      "\n",
      "Total des règles phasées: 618\n"
     ]
    }
   ],
   "source": [
    "counter=0\n",
    "for i in range(1, 6):\n",
    "    rules = ruleset_full.filter(phase=i)\n",
    "    print(f\"\\nRègles pour la phase {i} : {len(rules)}\")\n",
    "    counter += len(rules)\n",
    "print(f\"\\nTotal des règles phasées: {counter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Règles pour le niveau de paranoïa 1 : 604\n",
      "\n",
      "Règles pour le niveau de paranoïa 2 : 692\n",
      "\n",
      "Règles pour le niveau de paranoïa 3 : 721\n",
      "\n",
      "Règles pour le niveau de paranoïa 4 : 730\n"
     ]
    }
   ],
   "source": [
    "rules=ruleset_full.filter(pl=1)\n",
    "print(f\"\\nRègles pour le niveau de paranoïa 1 : {len(rules)}\")\n",
    "rules=ruleset_full.filter(pl=2)\n",
    "print(f\"\\nRègles pour le niveau de paranoïa 2 : {len(rules)}\")\n",
    "rules=ruleset_full.filter(pl=3)\n",
    "print(f\"\\nRègles pour le niveau de paranoïa 3 : {len(rules)}\")\n",
    "rules=ruleset_full.filter(pl=4)\n",
    "print(f\"\\nRègles pour le niveau de paranoïa 4 : {len(rules)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RuleSet (70 rules from 13 file(s))\n",
      "  Types:\n",
      "    SecRule: 70\n",
      "\n",
      "  Tags:\n",
      "    attack:\n",
      "      protocol: 28\n",
      "      rce: 8\n",
      "      sqli: 4\n",
      "      generic: 2\n",
      "      rfi: 2\n",
      "      fixation: 2\n",
      "      multipart-header: 1\n",
      "      xss: 1\n",
      "      disclosure: 1\n",
      "      (no tag): 21\n",
      "    application:\n",
      "      multi: 48\n",
      "      (no tag): 22\n",
      "    language:\n",
      "      multi: 45\n",
      "      java: 2\n",
      "      aspnet: 1\n",
      "      shell: 1\n",
      "      (no tag): 21\n",
      "    platform:\n",
      "      multi: 43\n",
      "      apache: 2\n",
      "      windows: 2\n",
      "      unix: 1\n",
      "      tomcat: 1\n",
      "      iis: 1\n",
      "      (no tag): 21\n"
     ]
    }
   ],
   "source": [
    "rules=ruleset_full.filter(action=\"chain\")\n",
    "print(rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse visuelle — Impact du Paranoia Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# CRS rules only\n",
    "crs = ruleset_full.filter(filename=\"crs_rules\")\n",
    "\n",
    "# Cumulative rulesets per PL (filter(pl=N) returns rules with PL <= N)\n",
    "pl_rulesets = {pl: crs.filter(pl=pl) for pl in range(1, 5)}\n",
    "\n",
    "# Severity order for consistent plotting\n",
    "SEVERITY_ORDER = [\"CRITICAL\", \"ERROR\", \"WARNING\", \"NOTICE\", \"(none)\"]\n",
    "SEVERITY_COLORS = {\n",
    "    \"CRITICAL\": \"#d32f2f\",\n",
    "    \"ERROR\": \"#f57c00\",\n",
    "    \"WARNING\": \"#fbc02d\",\n",
    "    \"NOTICE\": \"#64b5f6\",\n",
    "    \"(none)\": \"#bdbdbd\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 4 — Severity Distribution globale\n",
    "sev_dist = crs.severity_distribution\n",
    "sev_labels = [s for s in SEVERITY_ORDER if sev_dist.get(s, 0) > 0]\n",
    "sev_values = [sev_dist[s] for s in sev_labels]\n",
    "sev_colors = [SEVERITY_COLORS[s] for s in sev_labels]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 3))\n",
    "bars = ax.barh(sev_labels, sev_values, color=sev_colors)\n",
    "ax.bar_label(bars, fmt=\"%d\", padding=4)\n",
    "ax.set_xlabel(\"Nombre d'action rules\")\n",
    "ax.set_title(\"Distribution des sévérités — CRS Rules\")\n",
    "ax.invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Plot 1 — Composition du Ruleset par Paranoia Level (donut charts)\nfig, axes = plt.subplots(1, 4, figsize=(16, 4))\n\nfor i, pl in enumerate(range(1, 5)):\n    ax = axes[i]\n    sev = pl_rulesets[pl].severity_distribution\n    total = sum(sev.values())\n\n    labels = [s for s in SEVERITY_ORDER if sev.get(s, 0) > 0]\n    sizes = [sev[s] for s in labels]\n    colors = [SEVERITY_COLORS[s] for s in labels]\n\n    wedges, texts, autotexts = ax.pie(\n        sizes,\n        labels=None,\n        colors=colors,\n        autopct=lambda pct: f\"{int(round(pct * total / 100))}\",\n        pctdistance=0.75,\n        startangle=90,\n        wedgeprops={\"width\": 0.45, \"edgecolor\": \"white\", \"linewidth\": 1.5},\n    )\n    for t in autotexts:\n        t.set_fontsize(8)\n\n    # Total au centre\n    ax.text(0, 0, str(total), ha=\"center\", va=\"center\", fontsize=16, fontweight=\"bold\")\n    ax.set_title(f\"PL{pl}\", fontsize=13, fontweight=\"bold\")\n\n# Légende commune\nfig.legend(\n    [plt.Rectangle((0, 0), 1, 1, fc=SEVERITY_COLORS[s]) for s in SEVERITY_ORDER if crs.severity_distribution.get(s, 0) > 0],\n    [s for s in SEVERITY_ORDER if crs.severity_distribution.get(s, 0) > 0],\n    loc=\"center right\",\n    title=\"Severity\",\n    bbox_to_anchor=(1.02, 0.5),\n)\nfig.suptitle(\"Composition du Ruleset par Paranoia Level\", fontsize=14, fontweight=\"bold\", y=1.02)\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 2 — Heatmap Attack Coverage × PL (cumulative)\n",
    "# Build matrix: rows = attack sub-types, columns = PL levels\n",
    "attack_types = [\n",
    "    t for t, _ in crs.tag_distribution(\"attack\").most_common()\n",
    "    if t != \"(untagged)\"\n",
    "]\n",
    "\n",
    "heatmap_data = {}\n",
    "for pl in range(1, 5):\n",
    "    dist = pl_rulesets[pl].tag_distribution(\"attack\")\n",
    "    heatmap_data[f\"PL{pl}\"] = {t: dist.get(t, 0) for t in attack_types}\n",
    "\n",
    "df_heatmap = pd.DataFrame(heatmap_data, index=attack_types)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, max(5, len(attack_types) * 0.4)))\n",
    "sns.heatmap(\n",
    "    df_heatmap,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"YlOrRd\",\n",
    "    linewidths=0.5,\n",
    "    ax=ax,\n",
    "    cbar_kws={\"label\": \"Nombre de rules\"},\n",
    ")\n",
    "ax.set_title(\"Couverture par type d'attaque × Paranoia Level\")\n",
    "ax.set_ylabel(\"Type d'attaque\")\n",
    "ax.set_xlabel(\"Paranoia Level (cumulatif)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 3 — Heatmap normalisée (% du PL4)\n",
    "# Each row normalized to 100% = PL4 count for that attack type\n",
    "df_normalized = df_heatmap.div(df_heatmap[\"PL4\"], axis=0) * 100\n",
    "# Replace NaN (0/0 for types with 0 rules at PL4) with 0\n",
    "df_normalized = df_normalized.fillna(0)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, max(5, len(attack_types) * 0.4)))\n",
    "sns.heatmap(\n",
    "    df_normalized,\n",
    "    annot=True,\n",
    "    fmt=\".0f\",\n",
    "    cmap=\"RdYlGn\",\n",
    "    vmin=0,\n",
    "    vmax=100,\n",
    "    linewidths=0.5,\n",
    "    ax=ax,\n",
    "    cbar_kws={\"label\": \"% de couverture (PL4 = 100%)\"},\n",
    ")\n",
    "ax.set_title(\"% de couverture atteint par Paranoia Level (PL4 = 100%)\")\n",
    "ax.set_ylabel(\"Type d'attaque\")\n",
    "ax.set_xlabel(\"Paranoia Level (cumulatif)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## Étude de cas : Faux positif SQLi sur un champ de recherche\n\n**Scénario** : Une application e-commerce expose un endpoint de recherche `/api/search?q=...`.\nUn utilisateur légitime effectue la requête :\n\n```\nGET /api/search?q=SELECT+model+FROM+our+catalog+WHERE+price+UNION+ALL\n```\n\nCe type de requête — parfaitement légitime dans un contexte métier (documentation SQL, outil d'administration, CMS technique) — déclenche plusieurs règles CRS de la catégorie **REQUEST-942 (SQL Injection)**.\n\n**Objectif** : Identifier les règles responsables, calculer le score d'anomalie résultant, et choisir la stratégie d'exclusion appropriée parmi les 4 approches CRS.\n\n**Paramètres** : Paranoia Level 2, seuil d'anomalie inbound par défaut (5).",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# === Paramètres de l'étude de cas ===\nPARANOIA_LEVEL = 2\nINBOUND_ANOMALY_THRESHOLD = 5  # Seuil par défaut CRS\n\n# Correspondance severity → score d'anomalie (CRS standard)\nSEVERITY_SCORE = {\n    \"CRITICAL\": 5,\n    \"ERROR\": 4,\n    \"WARNING\": 3,\n    \"NOTICE\": 2,\n}\n\n# Filtrer les règles CRS au PL choisi\ncrs_pl = ruleset_full.filter(filename=\"crs_rules\", pl=PARANOIA_LEVEL)\nprint(f\"Règles CRS actives à PL{PARANOIA_LEVEL}: {len(crs_pl)}\")\nprint(f\"Seuil d'anomalie inbound: {INBOUND_ANOMALY_THRESHOLD}\")\n\n# Distribution des sévérités à ce PL\nsev = crs_pl.severity_distribution\nprint(f\"\\nDistribution des sévérités à PL{PARANOIA_LEVEL}:\")\nfor s in SEVERITY_ORDER:\n    count = sev.get(s, 0)\n    if count > 0:\n        score = SEVERITY_SCORE.get(s, 0)\n        print(f\"  {s:<10}: {count:>3} règles (score unitaire: +{score})\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Etape 1 — Identifier les règles SQLi actives au PL choisi",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Règles SQLi (fichier 942) actives à PL2\nsqli_rules = crs_pl.filter(filename=\"942\")\nprint(f\"=== REQUEST-942: SQL Injection (PL{PARANOIA_LEVEL}) ===\\n\")\nprint(sqli_rules)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Identifier les règles qui inspectent ARGS (paramètres de requête)\n# Ce sont celles susceptibles de matcher notre ?q=SELECT+model+FROM...\nargs_sqli_rules = []\nfor rule in sqli_rules:\n    if isinstance(rule, SecRule):\n        var_names = [v.variable for v in rule.variables]\n        if any(v in (\"ARGS\", \"ARGS_GET\", \"ARGS_NAMES\", \"REQUEST_URI\",\n                      \"REQUEST_LINE\", \"QUERY_STRING\", \"REQUEST_BODY\")\n               for v in var_names):\n            args_sqli_rules.append(rule)\n\nprint(f\"Règles SQLi inspectant les paramètres de requête: {len(args_sqli_rules)}\")\nprint(f\"(sur {len(sqli_rules)} règles SQLi totales au PL{PARANOIA_LEVEL})\\n\")\n\n# Afficher les règles potentiellement déclenchées\nfor rule in args_sqli_rules[:15]:\n    rule_id = rule.get_action(\"id\")\n    msg = rule.get_action(\"msg\")\n    severity = rule.get_action(\"severity\")\n    score = SEVERITY_SCORE.get(severity, 0)\n    variables = \", \".join(\n        v.variable + (f\":{v.variable_part}\" if v.variable_part else \"\")\n        for v in rule.variables\n    )\n    op_arg = rule.operator.operator_argument\n    op_display = op_arg[:70] + \"...\" if len(op_arg) > 70 else op_arg\n\n    print(f\"  [{rule_id}] {msg}\")\n    print(f\"    Severity: {severity} (+{score})  |  Variables: {variables}\")\n    print(f\"    Operator: {rule.operator.operator} \\\"{op_display}\\\"\")\n    print()\n\nif len(args_sqli_rules) > 15:\n    print(f\"  ... et {len(args_sqli_rules) - 15} autres règles\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Etape 2 — Calculer le score d'anomalie potentiel\n\nLe CRS fonctionne en **anomaly scoring** : chaque règle déclenchée incrémente un compteur (`tx.anomaly_score`) selon sa sévérité. Si le score cumulé atteint le seuil (`tx.inbound_anomaly_score_threshold`, défaut: 5), la requête est bloquée.\n\n| Severity | Score |\n|----------|-------|\n| CRITICAL | +5    |\n| ERROR    | +4    |\n| WARNING  | +3    |\n| NOTICE   | +2    |",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Distribution des sévérités parmi les règles SQLi ciblant ARGS\nsqli_args_ruleset = RuleSet(rules=args_sqli_rules)\nsev_dist = sqli_args_ruleset.severity_distribution\n\nprint(f\"=== Distribution des sévérités (SQLi sur ARGS, PL{PARANOIA_LEVEL}) ===\\n\")\nfor severity in SEVERITY_ORDER:\n    count = sev_dist.get(severity, 0)\n    if count > 0:\n        score = SEVERITY_SCORE.get(severity, 0)\n        print(f\"  {severity:<10}: {count:>3} règles  x  +{score}  =  {count * score:>4} points potentiels\")\n\ntotal_potential = sum(sev_dist.get(s, 0) * SEVERITY_SCORE.get(s, 0) for s in SEVERITY_ORDER)\nprint(f\"\\n  Score max si toutes déclenchées: {total_potential} points\")\nprint(f\"  Seuil de blocage:               {INBOUND_ANOMALY_THRESHOLD} points\")\nprint(f\"  --> Il suffit d'1 seule règle CRITICAL pour bloquer la requête\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Simulation : accumulation du score d'anomalie règle par règle\nprint(f\"=== Simulation : accumulation du score (pire cas, PL{PARANOIA_LEVEL}) ===\\n\")\n\ntotal_score = 0\ntriggered_rules = []\n\nfor rule in args_sqli_rules:\n    severity = rule.get_action(\"severity\")\n    score = SEVERITY_SCORE.get(severity, 0)\n    if score > 0:\n        total_score += score\n        triggered_rules.append({\n            \"id\": rule.get_action(\"id\"),\n            \"msg\": rule.get_action(\"msg\"),\n            \"severity\": severity,\n            \"score\": score,\n            \"cumulative\": total_score,\n        })\n\nprint(f\"{'ID':<12} {'Severity':<10} {'Score':>5} {'Cumul':>6}  Message\")\nprint(\"-\" * 105)\nfor r in triggered_rules:\n    just_crossed = (r[\"cumulative\"] >= INBOUND_ANOMALY_THRESHOLD\n                    and (r[\"cumulative\"] - r[\"score\"]) < INBOUND_ANOMALY_THRESHOLD)\n    marker = \" <-- BLOQUE\" if just_crossed else \"\"\n    over = \" !!\" if r[\"cumulative\"] >= INBOUND_ANOMALY_THRESHOLD else \"\"\n    msg_short = (r[\"msg\"][:50] + \"...\") if r[\"msg\"] and len(r[\"msg\"]) > 50 else (r[\"msg\"] or \"\")\n    print(f\"{r['id']:<12} {r['severity']:<10} +{r['score']:<4} {r['cumulative']:>5}{over}  {msg_short}{marker}\")\n\nprint(f\"\\nScore total potentiel: {total_score}\")\nprint(f\"Seuil de blocage: {INBOUND_ANOMALY_THRESHOLD}\")\nprint(f\"Dépassement: {'OUI' if total_score >= INBOUND_ANOMALY_THRESHOLD else 'NON'} ({total_score - INBOUND_ANOMALY_THRESHOLD:+d} points)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Visualisation : accumulation du score d'anomalie\nif triggered_rules:\n    fig, ax = plt.subplots(figsize=(14, 5))\n\n    ids = [r[\"id\"] for r in triggered_rules]\n    cumulative = [r[\"cumulative\"] for r in triggered_rules]\n    scores = [r[\"score\"] for r in triggered_rules]\n    colors = [SEVERITY_COLORS.get(r[\"severity\"], \"#999\") for r in triggered_rules]\n\n    ax.bar(range(len(ids)), scores, color=colors, alpha=0.7, label=\"Score individuel\")\n    ax.plot(range(len(ids)), cumulative, \"k-o\", markersize=4, linewidth=1.5, label=\"Score cumulé\")\n    ax.axhline(\n        y=INBOUND_ANOMALY_THRESHOLD, color=\"red\", linestyle=\"--\",\n        linewidth=2, label=f\"Seuil blocage ({INBOUND_ANOMALY_THRESHOLD})\"\n    )\n\n    # Zone de blocage\n    ax.axhspan(INBOUND_ANOMALY_THRESHOLD, max(cumulative) * 1.1,\n               alpha=0.08, color=\"red\", label=\"Zone de blocage\")\n\n    ax.set_xticks(range(len(ids)))\n    ax.set_xticklabels(ids, rotation=90, fontsize=7)\n    ax.set_xlabel(\"Rule ID\")\n    ax.set_ylabel(\"Score d'anomalie\")\n    ax.set_title(f\"Accumulation du score d'anomalie — SQLi sur ARGS (PL{PARANOIA_LEVEL})\")\n    ax.legend(loc=\"upper left\")\n    plt.tight_layout()\n    plt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Etape 3 — Analyse par tag : score atteignable par catégorie d'attaque\n\nUtilisons `tag_distribution` pour comprendre la surface d'attaque par catégorie et le score d'anomalie maximum atteignable pour chacune.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Score d'anomalie max atteignable par catégorie d'attaque (PL2)\n# Pour chaque tag attack-*, on calcule le score total si toutes les règles matchent\n\nattack_dist = crs_pl.tag_distribution(\"attack\")\nattack_types_sorted = [t for t, _ in attack_dist.most_common() if t != \"(untagged)\"]\n\n# Pour chaque type d'attaque, calculer le score max\nattack_scores = {}\nfor attack_type in attack_types_sorted:\n    tag_full = f\"attack-{attack_type}\"\n    # Trouver les règles avec ce tag\n    matching_rules = [\n        r for r in crs_pl.action_rules\n        if any(t.startswith(tag_full) for t in r.tags)\n    ]\n    total_score = sum(\n        SEVERITY_SCORE.get(r.get_action(\"severity\"), 0)\n        for r in matching_rules\n    )\n    attack_scores[attack_type] = {\n        \"count\": len(matching_rules),\n        \"score\": total_score,\n        \"severities\": Counter(r.get_action(\"severity\") or \"(none)\" for r in matching_rules),\n    }\n\nprint(f\"=== Score d'anomalie max par type d'attaque (PL{PARANOIA_LEVEL}) ===\\n\")\nprint(f\"{'Type attaque':<25} {'Rules':>6} {'Score max':>10}  Détail sévérités\")\nprint(\"-\" * 85)\nfor attack_type in attack_types_sorted:\n    info = attack_scores[attack_type]\n    sev_detail = \", \".join(\n        f\"{s}:{c}\" for s, c in info[\"severities\"].most_common() if s != \"(none)\"\n    )\n    bar = \"#\" * (info[\"score\"] // 5)\n    print(f\"  {attack_type:<23} {info['count']:>6} {info['score']:>10}  {bar}  {sev_detail}\")\n\n# Highlight SQLi\nsqli_info = attack_scores.get(\"sqli\", {})\nprint(f\"\\n--> SQLi : {sqli_info.get('count', 0)} règles, score max {sqli_info.get('score', 0)} points\")\nprint(f\"    Avec un seuil de {INBOUND_ANOMALY_THRESHOLD}, il suffit que quelques règles matchent pour bloquer\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Visualisation : score max atteignable par type d'attaque\nfig, ax = plt.subplots(figsize=(10, 6))\n\ntypes = list(reversed(attack_types_sorted))\nscores_list = [attack_scores[t][\"score\"] for t in types]\ncounts = [attack_scores[t][\"count\"] for t in types]\n\n# Color bars: highlight sqli\nbar_colors = [\"#d32f2f\" if t == \"sqli\" else \"#1976d2\" for t in types]\n\nbars = ax.barh(types, scores_list, color=bar_colors, alpha=0.8)\n\n# Annoter avec le nombre de règles et le score\nfor i, (bar, score, count) in enumerate(zip(bars, scores_list, counts)):\n    if score > 0:\n        ax.text(score + 2, bar.get_y() + bar.get_height() / 2,\n                f\"{score} pts ({count} rules)\", va=\"center\", fontsize=8)\n\nax.axvline(x=INBOUND_ANOMALY_THRESHOLD, color=\"red\", linestyle=\"--\",\n           linewidth=1.5, label=f\"Seuil blocage ({INBOUND_ANOMALY_THRESHOLD})\")\nax.set_xlabel(\"Score d'anomalie max atteignable\")\nax.set_title(f\"Score d'anomalie max par type d'attaque — CRS PL{PARANOIA_LEVEL}\\n(SQLi en rouge)\")\nax.legend()\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Etape 4 — Stratégies d'exclusion du faux positif\n\nLe CRS propose **4 approches** pour gérer les faux positifs, selon 2 axes :\n\n|  | **Suppression de règle** | **Mise à jour de cible** |\n|--|--------------------------|--------------------------|\n| **Configure-time** | `SecRuleRemoveById` / `SecRuleRemoveByTag` | `SecRuleUpdateTargetById` / `SecRuleUpdateTargetByTag` |\n| **Runtime** | `ctl:ruleRemoveById` / `ctl:ruleRemoveByTag` | `ctl:ruleRemoveTargetById` / `ctl:ruleRemoveTargetByTag` |\n\n**Axes de décision :**\n- **Suppression vs Target Update** : supprimer la règle entièrement, ou seulement exclure la variable problématique ?\n- **Configure-time vs Runtime** : appliquer globalement, ou conditionnellement (par URI, IP, etc.) ?",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# === Stratégie 1 — Suppression par ID (configure-time) ===\nprint(\"=\" * 80)\nprint(\"STRATEGIE 1 — SecRuleRemoveById (configure-time)\")\nprint(\"=\" * 80)\nprint()\nprint(\"# Désactiver les règles SQLi/ARGS une par une\")\nprint(\"# A placer APRES l'inclusion des règles CRS\\n\")\nfor rule in args_sqli_rules[:5]:\n    rid = rule.get_action(\"id\")\n    if rid:\n        print(f\"SecRuleRemoveById {rid}\")\nprint(f\"# ... ({len(args_sqli_rules)} règles au total)\")\nprint()\nprint(\"RISQUE : supprime TOUTE la protection SQLi sur TOUTES les variables,\")\nprint(\"         pas seulement pour le champ 'q', et pour TOUS les endpoints.\")\n\nprint(\"\\n\")\nprint(\"=\" * 80)\nprint(\"STRATEGIE 2 — SecRuleRemoveByTag (configure-time)\")\nprint(\"=\" * 80)\nprint()\n\n# Tags SQLi présents sur ces règles\nsqli_tags = set()\nfor rule in args_sqli_rules:\n    for tag in rule.tags:\n        if \"sqli\" in tag.lower() or \"sql\" in tag.lower():\n            sqli_tags.add(tag)\nprint(f\"Tags SQLi trouvés: {sorted(sqli_tags)}\\n\")\nfor tag in sorted(sqli_tags)[:3]:\n    print(f'SecRuleRemoveByTag \"{tag}\"')\nprint()\nprint(\"RISQUE : meme effet que stratégie 1, mais en une seule ligne.\")\nprint(\"         Supprime toutes les règles avec ce tag.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# === Stratégie 3 — SecRuleUpdateTargetById (configure-time) ===\nprint(\"=\" * 80)\nprint(\"STRATEGIE 3 — SecRuleUpdateTargetById (configure-time)  [RECOMMANDEE]\")\nprint(\"=\" * 80)\nprint()\nprint(\"# Exclure seulement le paramètre 'q' des règles SQLi\")\nprint(\"# Les règles restent actives sur tous les AUTRES paramètres\\n\")\nfor rule in args_sqli_rules[:5]:\n    rid = rule.get_action(\"id\")\n    if rid:\n        print(f'SecRuleUpdateTargetById {rid} \"!ARGS:q\"')\nprint(f\"# ... ({len(args_sqli_rules)} règles au total)\")\nprint()\n\n# Montrer combien de règles ciblent plusieurs variables\nmulti_var = [r for r in args_sqli_rules if len(r.variables) > 1]\nsingle_var = [r for r in args_sqli_rules if len(r.variables) == 1]\nprint(f\"Variables ciblées par ces règles :\")\nprint(f\"  {len(multi_var)} règles ciblent PLUSIEURS variables (protection conservée sur les autres)\")\nprint(f\"  {len(single_var)} règles ciblent UNE seule variable\")\nprint()\nprint(\"AVANTAGE : exclusion chirurgicale, couverture SQLi intacte sur les autres params.\")\nprint(\"LIMITE   : s'applique globalement à tous les endpoints.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# === Stratégie 4 — Runtime conditionnel (ctl:) ===\nprint(\"=\" * 80)\nprint(\"STRATEGIE 4 — ctl:ruleRemoveTargetByTag (runtime)  [LA PLUS PRECISE]\")\nprint(\"=\" * 80)\nprint()\nprint(\"# Exclure ARGS:q seulement pour l'endpoint /api/search\")\nprint(\"# La protection SQLi reste intacte partout ailleurs\\n\")\n\n# Identifier le meilleur tag pour cibler toutes les règles SQLi\nattack_sqli_tag = \"attack-sqli\"\nsqli_tag_count = sum(\n    1 for r in args_sqli_rules\n    if any(t == attack_sqli_tag for t in r.tags)\n)\n\nprint('SecRule REQUEST_URI \"@beginsWith /api/search\" \\\\')\nprint('    \"id:1000,\\\\')\nprint('     phase:1,\\\\')\nprint('     nolog,\\\\')\nprint('     pass,\\\\')\nprint(f'     ctl:ruleRemoveTargetByTag={attack_sqli_tag};ARGS:q\"')\nprint()\nprint(f\"Couverture du tag '{attack_sqli_tag}' : {sqli_tag_count}/{len(args_sqli_rules)} règles SQLi/ARGS\")\nprint()\nprint(\"AVANTAGE : scope minimal — seul ARGS:q sur /api/search est exclu.\")\nprint(\"           Protection SQLi intacte sur tous les autres endpoints ET paramètres.\")\nprint(\"           Une seule directive grâce au ciblage par tag.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Etape 5 — Comparaison d'impact sur la couverture de sécurité",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# === Comparaison d'impact des stratégies ===\nprint(f\"=== Impact sur la couverture de sécurité (PL{PARANOIA_LEVEL}) ===\\n\")\n\ntotal_crs = len(crs_pl)\ntotal_sqli_args = len(args_sqli_rules)\n\n# Score de protection perdu par stratégie\nscore_lost_remove = sum(\n    SEVERITY_SCORE.get(r.get_action(\"severity\"), 0) for r in args_sqli_rules\n)\n\n# Stratégie 1 & 2: Remove rules entirely\nremaining_remove = total_crs - total_sqli_args\ncoverage_remove = remaining_remove / total_crs * 100\n\nprint(f\"{'Stratégie':<50} {'Rules':>7} {'Couverture':>11} {'Scope'}\")\nprint(\"-\" * 100)\nprint(f\"{'Baseline (PL' + str(PARANOIA_LEVEL) + ')':<50} {total_crs:>7} {'100.0%':>11} {'Global'}\")\nprint(f\"{'1. SecRuleRemoveById (toutes SQLi/ARGS)':<50} {remaining_remove:>7} {coverage_remove:>10.1f}% {'Global — protection SQLi supprimée'}\")\nprint(f\"{'2. SecRuleRemoveByTag (idem par tag)':<50} {remaining_remove:>7} {coverage_remove:>10.1f}% {'Global — protection SQLi supprimée'}\")\nprint(f\"{'3. SecRuleUpdateTargetById !ARGS:q':<50} {total_crs:>7} {'~100.0%':>11} {'Global — ARGS:q exclu seulement'}\")\nprint(f\"{'4. ctl:ruleRemoveTargetByTag (runtime)':<50} {total_crs:>7} {'100.0%':>11} {'/api/search?q= exclu seulement'}\")\n\nprint(f\"\\n--- Détail ---\")\nprint(f\"Règles SQLi/ARGS supprimées (stratégie 1-2) : {total_sqli_args}\")\nprint(f\"Score de protection perdu : {score_lost_remove} points\")\nprint(f\"Règles multi-variables conservées (stratégie 3-4) : {len(multi_var)}/{total_sqli_args}\")\nprint(f\"\\nRecommandation : Stratégie 4 (runtime + target update par tag)\")\nprint(f\"  --> Scope minimal : un seul paramètre, un seul endpoint\")\nprint(f\"  --> Protection SQLi intacte partout ailleurs\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Visualisation : comparaison des stratégies\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# --- Panel gauche : couverture en nombre de règles ---\nstrategies = [\n    f\"Baseline\\nPL{PARANOIA_LEVEL}\",\n    \"1. RemoveById\\n(configure)\",\n    \"2. RemoveByTag\\n(configure)\",\n    \"3. UpdateTarget\\n(configure)\",\n    \"4. ctl:Target\\n(runtime)\",\n]\nrules_active = [total_crs, remaining_remove, remaining_remove, total_crs, total_crs]\nrules_colors = [\"#4caf50\", \"#f44336\", \"#f44336\", \"#ff9800\", \"#4caf50\"]\n\nbars = axes[0].bar(strategies, rules_active, color=rules_colors, alpha=0.85, edgecolor=\"white\")\naxes[0].bar_label(bars, fmt=\"%d\", padding=4)\naxes[0].set_ylabel(\"Nombre de règles actives\")\naxes[0].set_title(\"Règles actives après exclusion\")\naxes[0].set_ylim(0, total_crs * 1.15)\n\n# --- Panel droit : scope d'exclusion ---\nscope_labels = [\"Paramètres\\nexclus\", \"Endpoints\\naffectés\", \"Types attaque\\nexclus\"]\n# Stratégie 1-2 : tous les params, tous les endpoints, SQLi complet\n# Stratégie 3 : ARGS:q seulement, tous les endpoints\n# Stratégie 4 : ARGS:q seulement, /api/search seulement\n\nscope_data = {\n    \"1-2. Remove\": [100, 100, 100],  # tout exclu\n    \"3. UpdateTarget\": [5, 100, 0],   # 1 param, global, pas de type supprimé\n    \"4. ctl:Target\": [5, 5, 0],       # 1 param, 1 endpoint, pas de type supprimé\n}\n\nx = np.arange(len(scope_labels))\nwidth = 0.25\nfor i, (label, values) in enumerate(scope_data.items()):\n    color = [\"#f44336\", \"#ff9800\", \"#4caf50\"][i]\n    axes[1].bar(x + i * width, values, width, label=label, color=color, alpha=0.85)\n\naxes[1].set_ylabel(\"% de surface affectée par l'exclusion\")\naxes[1].set_title(\"Surface d'impact de l'exclusion (plus bas = mieux)\")\naxes[1].set_xticks(x + width)\naxes[1].set_xticklabels(scope_labels)\naxes[1].legend()\naxes[1].set_ylim(0, 130)\n\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Etape 6 — Approche par tag : analyse détaillée et exclusion groupée",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Analyse des tags présents sur les règles SQLi/ARGS pour une exclusion groupée\ntag_counter = Counter()\nfor rule in args_sqli_rules:\n    tag_counter.update(rule.tags)\n\n# Filtrer les tags pertinents (exclure les metadata CRS génériques)\nprint(\"=== Tags les plus fréquents sur les règles SQLi/ARGS ===\\n\")\nprint(f\"{'Tag':<55} {'Count':>5} {'%':>7}\")\nprint(\"-\" * 70)\nfor tag, count in tag_counter.most_common(20):\n    pct = count / len(args_sqli_rules) * 100\n    print(f\"  {tag:<53} {count:>5} ({pct:5.1f}%)\")\n\n# Vérifier si attack-sqli couvre toutes les règles\nattack_sqli_count = tag_counter.get(\"attack-sqli\", 0)\nprint(f\"\\n--> Le tag 'attack-sqli' couvre {attack_sqli_count}/{len(args_sqli_rules)} règles \"\n      f\"({attack_sqli_count/len(args_sqli_rules)*100:.0f}%)\")\n\n# Règles non couvertes par attack-sqli\nuncovered = [r for r in args_sqli_rules if \"attack-sqli\" not in r.tags]\nif uncovered:\n    print(f\"\\nRègles NON couvertes par 'attack-sqli' ({len(uncovered)}) :\")\n    for r in uncovered:\n        rid = r.get_action(\"id\")\n        msg = r.get_action(\"msg\")\n        tags = [t for t in r.tags if t.startswith(\"attack-\")]\n        print(f\"  [{rid}] {msg}\")\n        print(f\"    Tags attack: {tags}\")\nelse:\n    print(\"\\nToutes les règles sont couvertes par 'attack-sqli'.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Conclusion\n\n**Diagnostic** : Le paramètre `q` sur `/api/search` déclenche un faux positif massif sur les règles SQLi (REQUEST-942). Le score d'anomalie dépasse largement le seuil de blocage dès la première règle CRITICAL.\n\n**Recommandation** : **Stratégie 4** — exclusion runtime par tag avec mise à jour de cible :\n\n```apache\nSecRule REQUEST_URI \"@beginsWith /api/search\" \\\n    \"id:1000,\\\n     phase:1,\\\n     nolog,\\\n     pass,\\\n     ctl:ruleRemoveTargetByTag=attack-sqli;ARGS:q\"\n```\n\n**Pourquoi cette approche ?**\n- **Scope minimal** : seul `ARGS:q` est exclu, et uniquement sur `/api/search`\n- **Protection conservée** : les règles SQLi restent actives sur tous les autres paramètres et endpoints\n- **Maintenable** : le tag `attack-sqli` couvre automatiquement les futures mises à jour du CRS\n- **Une seule directive** : pas besoin de lister chaque ID de règle individuellement",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}